{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from model import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 1696), (7954, 1))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv로 만든 파일 불러오기.\n",
    "df = pd.read_csv('encoded.csv', index_col=0) # 0번째 열을 인덱스로 지정.\n",
    "vocaDF = pd.read_csv('vocab.csv', index_col=0)\n",
    "df.shape, vocaDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0'], dtype='object')"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocaDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\NLP_38\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model.pth'\n",
    "\n",
    "HIDDEN_SIZE = 64\n",
    "EMBEDD_DIM  = 128\n",
    "VOCAB_SIZE  = vocaDF.shape[0]\n",
    "NUM_LAYERS = 1\n",
    "EPOCHS      = 100\n",
    "LR          = 0.1\n",
    "BATCH_SIZE  = 1\n",
    "DROPOUT     = 0.5\n",
    "OUTPUT      = 8\n",
    "\n",
    "mdl = LSTM(VOCAB_SIZE, EMBEDD_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor((text), dtype=torch.int64).to(device)\n",
    "        text = text.unsqueeze(0)\n",
    "        offsets = torch.tensor([0]).to(device)\n",
    "        predicted_label = model(text)\n",
    "        return predicted_label.argmax(1).item()\n",
    "    \n",
    "# def predict(model, text, text_pipeline):\n",
    "#     with torch.no_grad():\n",
    "#         text = torch.tensor(text_pipeline(text), dtype=torch.int64).to(device)\n",
    "#         text = text.unsqueeze(0)\n",
    "#         offsets = torch.tensor([0]).to(device)\n",
    "#         predicted_label = model(text, offsets)\n",
    "#         return predicted_label.argmax(1).item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = '아름다운 청춘의 한 장 함께 써내려 가자 너와의 추억들로 가득 채울래 (come on!) 아무 걱정도 하지는 마, 나에게 다 맡겨 봐 지금 이 순간이 다시 넘겨볼 수 있는 한 페이지가 될 수 있게.'\n",
    "#text = '월요일엔 아마 바쁘지 않을까 화요일도 성급해 보이지 안 그래 수요일은 뭔가 어정쩡한 느낌 목요일은 그냥 내가 왠지 싫어'\n",
    "#text = '다 너의 반 반 반의 반의 반도 채워주질 못 하네 채워지지가 않네 Yeah 딱 너의 반 반 반의 반이라도 내게 남았더라면 이렇게 붕 떠있진 않을 텐데'\n",
    "text = '모두 할 말을 잃지 Like you 4차원 이상의 기적의 View 달콤히 찍어 문 빛의 퐁듀 보이기 시작한 음의 색도 예민해진 걸 느껴 뚜렷한 색감과 여섯 번째 감각'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokentext(text, vocaDF) :\n",
    "\n",
    "    from konlpy.tag import Kkma\n",
    "    kkma = Kkma()\n",
    "    texttoken = kkma.morphs(text)\n",
    "\n",
    "    # 어휘사전\n",
    "    vocab_dict = {word: idx for idx, word in enumerate(vocaDF['0'].to_list())}\n",
    "    encoded = [vocab_dict[token] for token in texttoken if token in vocab_dict]\n",
    "    # 인코딩 결과 출력\n",
    "    print(\"토큰화된 단어들:\", texttoken)\n",
    "    print(\"인코딩 결과:\", encoded)\n",
    "    padded_id=[]\n",
    "    max_length = df.shape[1]\n",
    "\n",
    "    if len(encoded) < max_length :\n",
    "        padded_id.append(encoded + [0]*(max_length-len(encoded)))\n",
    "    else :\n",
    "        padded_id.append(encoded)\n",
    "    return padded_id[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화된 단어들: ['모두', '하', 'ㄹ', '말', '을', '잃', '지', 'Like', 'you', '4', '차원', '이상', '의', '기적', '의', 'View', '닿', 'ㄹ', '콤히', '찍', '어', '문', '빛', '의', '퐁듀', '보이', '기', '시작', '하', 'ㄴ', '음의', '색도', '예민', '해지', 'ㄴ', '것', '을', '느끼', '어', '뚜렷', '하', 'ㄴ', '색감', '과', '여섯', '번째', '감각']\n",
      "인코딩 결과: [3135, 984, 53, 263, 4808, 93, 94, 732, 1090]\n"
     ]
    }
   ],
   "source": [
    "token = tokentext(text, vocaDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(mdl, token) #[0: 'ballad', 1:'dance', 2: 'fork', 3:'hiphop', 4:'indi', 5:'R&B', 6:'rock', 7:'trot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dance\n"
     ]
    }
   ],
   "source": [
    "if result == 0: print('ballad')\n",
    "elif result == 1 : print('dance')\n",
    "elif result == 2 : print('fork')\n",
    "elif result == 3 : print('hiphop')\n",
    "elif result == 4 : print('indi')\n",
    "elif result == 5 : print('R&B')\n",
    "elif result == 6 : print('rock')\n",
    "elif result == 7 : print('trot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

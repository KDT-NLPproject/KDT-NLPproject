{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.124599Z",
     "start_time": "2024-04-05T03:09:21.108922Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0  genre    1    2    3    4    5    6    7    8  ...  843  844  \\\n0           0      1    0    2    3    0    0    4    0    5  ...    1    1   \n1           1      1   31   41   42   43   44   45    0   46  ...    1    1   \n2           2      1  138  139  140    0    0    0  141    0  ...    1    1   \n3           3      1  117    0  203    0  204  205  206    0  ...    1    1   \n4           4      1  284    0  285  286  287    0  288  288  ...    1    1   \n\n   845  846  847  848  849  850  851  852  \n0    1    1    1    1    1    1    1    1  \n1    1    1    1    1    1    1    1    1  \n2    1    1    1    1    1    1    1    1  \n3    1    1    1    1    1    1    1    1  \n4    1    1    1    1    1    1    1    1  \n\n[5 rows x 854 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>genre</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>843</th>\n      <th>844</th>\n      <th>845</th>\n      <th>846</th>\n      <th>847</th>\n      <th>848</th>\n      <th>849</th>\n      <th>850</th>\n      <th>851</th>\n      <th>852</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>31</td>\n      <td>41</td>\n      <td>42</td>\n      <td>43</td>\n      <td>44</td>\n      <td>45</td>\n      <td>0</td>\n      <td>46</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>138</td>\n      <td>139</td>\n      <td>140</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>141</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>117</td>\n      <td>0</td>\n      <td>203</td>\n      <td>0</td>\n      <td>204</td>\n      <td>205</td>\n      <td>206</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>284</td>\n      <td>0</td>\n      <td>285</td>\n      <td>286</td>\n      <td>287</td>\n      <td>0</td>\n      <td>288</td>\n      <td>288</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 854 columns</p>\n</div>"
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv('./total_padded_encoded_df.csv')\n",
    "data = pd.DataFrame(result)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.314487Z",
     "start_time": "2024-04-05T03:09:21.219040Z"
    }
   },
   "id": "c65fef1ba31536f0",
   "execution_count": 466
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data['genre'] = data['genre'].replace({1:0, 2:1, 3:2, 4:3, 5:4, 6:5, 7:6, 8:7})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.330444Z",
     "start_time": "2024-04-05T03:09:21.314487Z"
    }
   },
   "id": "a98fa634a6f42206",
   "execution_count": 467
  },
  {
   "cell_type": "markdown",
   "source": [
    "# feature, label 분리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f13644b5b9cbcca"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(772, 852) (772, 1)\n"
     ]
    }
   ],
   "source": [
    "feature_df = data.iloc[:, 2:]\n",
    "label_df = data[['genre']]\n",
    "print(feature_df.shape, label_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.346549Z",
     "start_time": "2024-04-05T03:09:21.330444Z"
    }
   },
   "id": "6d31254c789d0efe",
   "execution_count": 468
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     1    2    3    4    5    6    7    8    9   10  ...  843  844  845  846  \\\n0    0    2    3    0    0    4    0    5    6    7  ...    1    1    1    1   \n1   31   41   42   43   44   45    0   46    0   47  ...    1    1    1    1   \n2  138  139  140    0    0    0  141    0  143    0  ...    1    1    1    1   \n3  117    0  203    0  204  205  206    0  118  207  ...    1    1    1    1   \n4  284    0  285  286  287    0  288  288  289  290  ...    1    1    1    1   \n\n   847  848  849  850  851  852  \n0    1    1    1    1    1    1  \n1    1    1    1    1    1    1  \n2    1    1    1    1    1    1  \n3    1    1    1    1    1    1  \n4    1    1    1    1    1    1  \n\n[5 rows x 852 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>843</th>\n      <th>844</th>\n      <th>845</th>\n      <th>846</th>\n      <th>847</th>\n      <th>848</th>\n      <th>849</th>\n      <th>850</th>\n      <th>851</th>\n      <th>852</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31</td>\n      <td>41</td>\n      <td>42</td>\n      <td>43</td>\n      <td>44</td>\n      <td>45</td>\n      <td>0</td>\n      <td>46</td>\n      <td>0</td>\n      <td>47</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>138</td>\n      <td>139</td>\n      <td>140</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>141</td>\n      <td>0</td>\n      <td>143</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>117</td>\n      <td>0</td>\n      <td>203</td>\n      <td>0</td>\n      <td>204</td>\n      <td>205</td>\n      <td>206</td>\n      <td>0</td>\n      <td>118</td>\n      <td>207</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>284</td>\n      <td>0</td>\n      <td>285</td>\n      <td>286</td>\n      <td>287</td>\n      <td>0</td>\n      <td>288</td>\n      <td>288</td>\n      <td>289</td>\n      <td>290</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 852 columns</p>\n</div>"
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.362216Z",
     "start_time": "2024-04-05T03:09:21.346549Z"
    }
   },
   "id": "7e97bdb90f217b31",
   "execution_count": 469
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   genre\n0      0\n1      0\n2      0\n3      0\n4      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.377916Z",
     "start_time": "2024-04-05T03:09:21.362216Z"
    }
   },
   "id": "8f93f08d6d24cf41",
   "execution_count": 470
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# label_df = label_df.replace({1:0, 2:1, 3:2, 4:3, 5:4, 6:5, 7:6, 8:7})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.393867Z",
     "start_time": "2024-04-05T03:09:21.377916Z"
    }
   },
   "id": "33034aeee3d94738",
   "execution_count": 471
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64)"
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df['genre'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.409800Z",
     "start_time": "2024-04-05T03:09:21.393867Z"
    }
   },
   "id": "e616c58a0c1a632f",
   "execution_count": 472
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   genre\n0      0\n1      0\n2      0\n3      0\n4      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.425669Z",
     "start_time": "2024-04-05T03:09:21.409800Z"
    }
   },
   "id": "8cdaae7a69b0f5a0",
   "execution_count": 473
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DataSet 생성, Tensor 변환, DataLoader 생성"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8605f744e291a0f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torch\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = data.iloc[:, 2:].values\n",
    "        self.y_data = data[['genre']].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = torch.LongTensor(self.x_data[idx])\n",
    "        y = torch.LongTensor(self.y_data[idx])\n",
    "        return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.441386Z",
     "start_time": "2024-04-05T03:09:21.425669Z"
    }
   },
   "id": "98a1f30800b6e1c1",
   "execution_count": 474
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694\n"
     ]
    }
   ],
   "source": [
    "DS = CustomDataset()\n",
    "\n",
    "num = int(len(DS) * 0.9)\n",
    "print(num)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.457180Z",
     "start_time": "2024-04-05T03:09:21.441386Z"
    }
   },
   "id": "90dd901d8aa17723",
   "execution_count": 475
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 학습용과 테스트용으로 분리\n",
    "train_ds, test_ds = random_split(DS, [num, len(DS) - num])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.521295Z",
     "start_time": "2024-04-05T03:09:21.505179Z"
    }
   },
   "id": "46aba4978721aca9",
   "execution_count": 476
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 데이터 로더 생성\n",
    "BATCH = 20\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle = True)\n",
    "test_loader = DataLoader(test_ds, batch_size = BATCH, shuffle = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.616543Z",
     "start_time": "2024-04-05T03:09:21.600826Z"
    }
   },
   "id": "dad8949721b5c2e4",
   "execution_count": 477
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 설계"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31f71710a9c4b6ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class music_rnn(nn.Module):\n",
    "    def __init__(self, VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASS):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=EMBED_DIM)\n",
    "        self.rnn = nn.RNN(input_size=EMBED_DIM, hidden_size=HIDDEN_SIZE, batch_first = True)\n",
    "        # 학습 모델을 RNN 대신에 LSTM을 사용해볼수도 있겠다\n",
    "        # RNN에서 양방향 학습 파라미터를 설정해볼 수 도 있겠다.\n",
    "        \n",
    "        # 활성화함수 => 다중 분류니까\n",
    "        # self.fc = nn.Softmax(HIDDEN_SIZE, NUM_CLASS) # 이렇게 쓰는게 아닌가?\n",
    "        self.fc = nn.Linear(HIDDEN_SIZE, NUM_CLASS) # 다중 분류인데 이게 되나?\n",
    "        \n",
    "        self.init_weights() # 이건 왜 쓴거지?\n",
    "        self.dropout = nn.Dropout()  # 혹시 모를 과대적합을 위해서\n",
    "        \n",
    "    # 가중치 초기화\n",
    "    def init_weights(self):\n",
    "        range = 0.5\n",
    "        self.embedding.weight.data.uniform_(-range, range)\n",
    "        # self.fc.weight.data.uniform_(-range, range)\n",
    "        # self.fc.bias.data.zero_()\n",
    "        \n",
    "    # 순방향 학습 진행\n",
    "    def forward(self, text):\n",
    "        embed = self.embedding(text)\n",
    "        print(f\"embed shape : {embed.shape}\")\n",
    "        output, hidden = self.rnn(embed)\n",
    "        print(f\"output shape : {output.shape}\")\n",
    "        print(f\"hidden shape : {hidden.shape}\")\n",
    "        output=output[:,-1,:]\n",
    "        result = self.fc(output)\n",
    "        print('[ class에서 forward 진행 후 결과 ]')\n",
    "        \n",
    "        print(f\"result shape : {result.shape}\")# 이 층을 왜 통과시켜줘야하는거지? ;;\n",
    "        # result = F.softmax(self.fc(output), dim=1)\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.728004Z",
     "start_time": "2024-04-05T03:09:21.696347Z"
    }
   },
   "id": "56fe7d4666bf3171",
   "execution_count": 478
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 학습용 변수들 지정\n",
    "from torch import optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "VOCAB_SIZE = 13714\n",
    "EMBED_DIM = 50\n",
    "HIDDEN_SIZE = 10\n",
    "NUM_CLASS = 8\n",
    "model = music_rnn(VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASS)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(params = model.parameters())\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.823559Z",
     "start_time": "2024-04-05T03:09:21.794202Z"
    }
   },
   "id": "2e2f1701cefa5cb1",
   "execution_count": 479
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "music_rnn(\n  (embedding): Embedding(13714, 50)\n  (rnn): RNN(50, 10, batch_first=True)\n  (fc): Linear(in_features=10, out_features=8, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n)"
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:21.903060Z",
     "start_time": "2024-04-05T03:09:21.887001Z"
    }
   },
   "id": "73f39c723f6c868b",
   "execution_count": 480
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 함수 지정 (train, test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9df80cc45c27fead"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 8])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "label shape : torch.Size([20, 1])\n",
      "embed shape : torch.Size([20, 852, 50])\n",
      "output shape : torch.Size([20, 852, 10])\n",
      "hidden shape : torch.Size([1, 20, 10])\n",
      "[ class에서 forward 진행 후 결과 ]\n",
      "result shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n",
      "[ 학습 함수 안에서 결과 ]\n",
      "feature shape : torch.Size([20, 852])\n",
      "label2 shape : torch.Size([20, 7])\n",
      "pred shape : torch.Size([20, 8])\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[481], line 44\u001B[0m\n\u001B[0;32m     41\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output_list\n\u001B[1;32m---> 44\u001B[0m \u001B[43mtraining\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[481], line 31\u001B[0m, in \u001B[0;36mtraining\u001B[1;34m(DATALOADER)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m50\u001B[39m)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# pred = label.view(-1,8).float()\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# print(feature, label, pred, sep = '\\n\\n', end =  '\\n\\n')\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# print('-'*50)\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# print(f\"feature.shape - {feature.shape}  label.shape - {label.shape}  pred.shape - {pred.shape}\")\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# 손실 검정\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \n\u001B[0;32m     32\u001B[0m output_list[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[0;32m     33\u001B[0m output_list[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(metrics\u001B[38;5;241m.\u001B[39maccuracy(pred, label2, task \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m   1178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m-> 1179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1180\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1181\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torch\\nn\\functional.py:3059\u001B[0m, in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   3057\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3058\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3059\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "import torchmetrics.functional.classification as metrics\n",
    "import numpy as np\n",
    "def training(DATALOADER):\n",
    "    model.train()\n",
    "    output_list = [[], [], [], [], []]\n",
    "    # loss, acc, precision, recall, f1_score\n",
    "    for (feature, label) in DATALOADER:\n",
    "        label2 = F.one_hot(label)\n",
    "        label2 = label2.squeeze(dim=1)\n",
    "        print(f\"label shape : {label.shape}\")\n",
    "        # label = label.expand(-1,8)\n",
    "        \n",
    "        feature = feature.to(device)\n",
    "        label2 = label2.to(device)\n",
    "\n",
    "        pred = model(feature)\n",
    "        print('-'*50)\n",
    "        print('[ 학습 함수 안에서 결과 ]')\n",
    "        print(f\"feature shape : {feature.shape}\")\n",
    "        # print(f\"label shape : {label.shape}\")\n",
    "        print(f\"label2 shape : {label2.shape}\")\n",
    "        print(f\"pred shape : {pred.shape}\")\n",
    "        print('-'*50)\n",
    "        \n",
    "        # pred = label.view(-1,8).float()\n",
    "        # print(feature, label, pred, sep = '\\n\\n', end =  '\\n\\n')\n",
    "        # print('-'*50)\n",
    "        # print(f\"feature.shape - {feature.shape}  label.shape - {label.shape}  pred.shape - {pred.shape}\")\n",
    "        \n",
    "        # 손실 검정\n",
    "        loss = loss_fn(pred, label2.float()) \n",
    "        output_list[0].append(loss.item())\n",
    "        output_list[1].append(metrics.accuracy(pred, label2, task = 'binary').item())\n",
    "        output_list[2].append(metrics.precision(pred, label2, task = 'binary').item())\n",
    "        output_list[3].append(metrics.recall(pred, label2, task = 'binary').item())\n",
    "        output_list[4].append(metrics.f1_score(pred, label2, task = 'binary').item())\n",
    "        \n",
    "        # 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return output_list\n",
    "training(train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T03:09:23.514140Z",
     "start_time": "2024-04-05T03:09:21.904713Z"
    }
   },
   "id": "73f7f55acbfe51e",
   "execution_count": 481
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ec79e0a675ca239",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-05T03:09:23.517234Z"
    }
   },
   "id": "fda4c6a330eec192",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
